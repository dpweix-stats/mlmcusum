#' Train methods
#'
#' Train the mrfMCUSUM, gruMCUSUM method. Also works for the resMCUSUM method
#' from Bodnar et al. (2017), which uses a VARMA(1, 1). 
#' 
#'
#' @param data A multivariate time series in dataframe or matrix form. 
#' @param lags The number of lags of each variable to be included in the design matrix.
#' @param k A tuning parameter for the MCUSUM, large k results in shorter memory.
#' @param r A tuning parameter for MEWMA, large r results in shorter memory.
#' @return A named list including the plotting statistic, trained model, residuals, and constants.
#' @name train
#' @rdname train

NULL

#' @rdname train
#' @export
train_gruMCUSUM <- function(data, lags = 1, k = .9) {
  l <- lags
  p <- ncol(data)
  
  constants <- c(k, l, p)
  names(constants) <- c("k", "lags", "p")
  
  X <- create_X(data, lags = l)
  Y <- create_Y(data, lags = l)
  
  
  fit_gru <- train_gru(X, Y, l) # python
  
  gru_preds <- pred_gru(fit_gru, X) # python
  colnames(gru_preds) <- colnames(data)

  # Get Tau
  tau <- calc_tau(Y - gru_preds)
  
  mu_tau <- colMeans(tau)
  sigma_tau_inv <- solve(cov(tau))

  # Get S
  S <- calc_S(tau, k, mu_tau, sigma_tau_inv)

  # Plotting Statistic
  pstat <- calc_PStat(S, sigma_tau_inv)
  
  # Return
  list(pstat = pstat,
      model = fit_gru,
      residuals = Y - gru_preds,
      mu_tau = mu_tau,
      sigma_tau_inv = sigma_tau_inv,
      constants = constants)
}

#' @rdname train
#' @export
train_mrfMCUSUM <- function(data, lags = 1, k = .9) {
  l <- lags
  p <- ncol(data)
  
  constants <- c(k, l, p)
  names(constants) <- c("k", "lags", "p")
  
  X <- create_X(data, lags = l)
  Y <- create_Y(data, lags = l)
  
  
  fit_mrf <-
    MultivariateRandomForest::build_single_tree(X, Y,
                                                m_feature = floor(sqrt(l*p)),
                                                min_leaf = 10,
                                                Inv_Cov_Y = solve(cov(Y)),
                                                Command = 2)
  
  mrf_preds <- MultivariateRandomForest::single_tree_prediction(fit_mrf, X, p)
  colnames(mrf_preds) <- colnames(data)
  
  # Get Tau
  tau <- calc_tau(Y - mrf_preds)
  
  mu_tau <- colMeans(tau)
  sigma_tau_inv <- solve(cov(tau))
  
  # Get S
  S <- calc_S(tau, k, mu_tau, sigma_tau_inv)
  
  # Plotting Statistic
  pstat <- calc_PStat(S, sigma_tau_inv)
  
  # Return
  list(pstat = pstat,
       model = fit_mrf,
       residuals = Y - mrf_preds,
       mu_tau = mu_tau,
       sigma_tau_inv = sigma_tau_inv,
       constants = constants)
}


#' @rdname train
#' @export
train_varmaMCUSUM <- function(data, k = 0.9) {
  l <- 1
  p <- ncol(data)
  
  constants <- c(k, l, p)
  names(constants) <- c("k", "lags", "p")
  
  # Fit Model
  fit_varma <-
    MTS::VARMACpp(data, p = 1, q = 1, include.mean = TRUE)
  
  residuals <- fit_varma$residuals
  colnames(residuals) <- colnames(data)
  
  # Get Tau
  tau <- calc_tau(residuals)
  
  mu_tau <- colMeans(tau)
  sigma_tau_inv <- solve(cov(tau))
  
  # Get S
  S <- calc_S(tau, k, mu_tau, sigma_tau_inv)
  
  # Plotting Statistic
  pstat <- calc_PStat(S, sigma_tau_inv)
  
  # Return
  list(pstat = pstat,
       model = fit_varma,
       residuals = residuals,
       mu_tau = mu_tau,
       sigma_tau_inv = sigma_tau_inv,
       constants = constants)
}


#' @rdname train
#' @export
train_varmaMEWMA <- function(data, r = 0.3) {
  l <- 1
  p <- ncol(data)
  
  constants <- c(r, l, p)
  names(constants) <- c("r", "lags", "p")
  
  fit_varma <-
    MTS::VARMACpp(data, p = 1, q = 1, include.mean = TRUE)
  
  residuals <- fit_varma$residuals
  colnames(residuals) <- colnames(data)
  
  # Get Tau
  tau <- calc_tau(residuals)
  
  mu_tau <- colMeans(tau)
  sigma_tau_inv <- solve(cov(tau))
  
  # Get D
  D <- calc_D(tau, mu_tau, sigma_tau_inv)
  
  # Plotting Statistic
  pstat <- calc_PStat_MEWMA(r, D, p)
  
  # Return
  list(pstat = pstat,
       D = D,
       model = fit_varma,
       residuals = residuals,
       mu_tau = mu_tau,
       sigma_tau_inv = sigma_tau_inv,
       constants = constants)
}
